{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will be performing data wrangling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Identify duplicate values in the dataset.\n",
    "\n",
    "*   Remove duplicate values from the dataset.\n",
    "\n",
    "*   Identify missing values in the dataset.\n",
    "\n",
    "*   Impute the missing values in the dataset.\n",
    "\n",
    "*   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many duplicate rows exist in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find duplicates take your dataframe and run duplicated method\n",
    "stored_duplicates = df.duplicated()\n",
    "\n",
    "# now you can sum this new data\n",
    "stored_duplicates.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can shorten all this with one single line\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates an objuect free of duplicates \n",
    "df.drop_duplicates()\n",
    "\n",
    "# now I will create an object free of duplicates and save it\n",
    "duplicate_free = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can simply take the duplicates out of your dataframe with inplace\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I will count how many duplicates are left to test\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent        0\n",
       "MainBranch        0\n",
       "Hobbyist          0\n",
       "OpenSourcer       0\n",
       "OpenSource       81\n",
       "               ... \n",
       "Sexuality       542\n",
       "Ethnicity       675\n",
       "Dependents      140\n",
       "SurveyLength     19\n",
       "SurveyEase       14\n",
       "Length: 85, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas.isnull - This function takes a scalar or array-like object and indicates whether values are missing \n",
    "# (NaN in numeric arrays, None or NaN in object arrays, NaT in datetimelike)\n",
    "\n",
    "\n",
    "\n",
    "# now i will use the Isnull function to find nan and na values \n",
    "# then I will use the sum function to count the missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will use the isnull with the sum function on a single column\n",
    "\n",
    "# this is how we can select a column - just use this syntax dataframe_name[\"column_name\"] \n",
    "selected_column = df[\"WorkLoc\"]\n",
    "\n",
    "# now we can use the isnull with the sum function to find out how many rows are missing\n",
    "selected_column.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can clean this up and make it look better by putting it into one line\n",
    "df[\"WorkLoc\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the  value counts for the column WorkLoc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office                                            6806\n",
       "Home                                              3589\n",
       "Other place, such as a coworking space or cafe     971\n",
       "Name: WorkLoc, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I will use the value count method\n",
    "# the value count method Returns a Series containing counts of unique values\n",
    "\n",
    "values_counts_workloc = df[\"WorkLoc\"].value_counts()\n",
    "\n",
    "# display \n",
    "values_counts_workloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Office'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can use the (index max) indxmax  method on our new object\n",
    "#to return the maximum (on the axis we want) \n",
    "values_counts_workloc.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Office'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as always we could also shorten this down to one line\n",
    "df[\"WorkLoc\"].value_counts().idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Office'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets save that variable for later \n",
    "common_value = df[\"WorkLoc\"].value_counts().idxmax()\n",
    "\n",
    "# display\n",
    "common_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  Home\n",
       "1                                                Office\n",
       "2                                                  Home\n",
       "3                                                  Home\n",
       "4        Other place, such as a coworking space or cafe\n",
       "                              ...                      \n",
       "11547                                              Home\n",
       "11548                                              Home\n",
       "11549                                            Office\n",
       "11550                                              Home\n",
       "11551                                            Office\n",
       "Name: WorkLoc, Length: 11398, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To replace the NA and Nan Values we can use pandas fillna method\n",
    "# the fillna method fills Na and Nan's with a value\n",
    "\n",
    "df[\"WorkLoc\"].fillna(value=common_value)\n",
    "# this will create an object that has the Na and Nan values replaced with the common value \"office\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets make those changes to our dataframe with inplace\n",
    "df[\"WorkLoc\"].fillna(value=common_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if imputing was successful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can check to make sure our changes worked\n",
    "df[\"WorkLoc\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\".\n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yearly     6073\n",
       "Monthly    4788\n",
       "Weekly      331\n",
       "Name: CompFreq, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can easily get the categories with the value count method\n",
    "df[\"CompFreq\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the **Hint**.\n",
    "\n",
    "<!--\n",
    "\n",
    "Use the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n",
    "\n",
    "If the CompFreq is Yearly then use the exising value in CompTotal\n",
    "If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
    "If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so to make a new column you can just use name_of_dataframe[name_of_column] = series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start with a function that can handle our logic \n",
    "\n",
    "def compensation_calc(frequency, compensation):\n",
    "    yearly_compensation = 0    \n",
    "\n",
    "    \n",
    "    # we can just keep the yearly as is\n",
    "    if frequency == \"Yearly\":        \n",
    "        yearly_compensation = compensation        \n",
    "        \n",
    "    # now we have to multiply by 12 for the month   \n",
    "    elif frequency == \"Monthly\":        \n",
    "        yearly_compensation = compensation * 12        \n",
    "        \n",
    "    # now we have to multiply by 52 for the weeks  \n",
    "    elif frequency == \"Weekly\":        \n",
    "        yearly_compensation = compensation * 52\n",
    "\n",
    "        \n",
    "    return yearly_compensation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The way I am going to do this is to make a list and add it to my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly 61000.0\n",
      "Yearly 138000.0\n",
      "Yearly 90000.0\n",
      "Monthly 29000.0\n",
      "Yearly 90000.0\n",
      "Monthly 9500.0\n",
      "Monthly 3000.0\n",
      "Yearly 103000.0\n",
      "Yearly 69000.0\n",
      "Monthly 8000.0\n",
      "Monthly 7000.0\n",
      "Yearly 114000.0\n",
      "Weekly 2000.0\n",
      "Weekly 22000.0\n",
      "Monthly 96000.0\n",
      "Yearly 156000.0\n",
      "Yearly 18000.0\n",
      "Monthly 6400.0\n",
      "Monthly 5000.0\n",
      "Yearly 400000.0\n"
     ]
    }
   ],
   "source": [
    "# with the itterrows we can itterarte through our dataframe\n",
    "#(use head to save time)\n",
    "for i, row in df.head(20).iterrows():\n",
    "    \n",
    "    #now lets move through each row and grab the values we need\n",
    "    period = row[\"CompFreq\"]\n",
    "    payment = row[\"CompTotal\"]\n",
    "    \n",
    "    \n",
    "    # lets test with a print\n",
    "    print (row[\"CompFreq\"], row[\"CompTotal\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person is earns (61000.0, 'Yearly'). That means they make 61000.0 a year\n",
      "This person is earns (138000.0, 'Yearly'). That means they make 138000.0 a year\n",
      "This person is earns (90000.0, 'Yearly'). That means they make 90000.0 a year\n",
      "This person is earns (29000.0, 'Monthly'). That means they make 348000.0 a year\n",
      "This person is earns (90000.0, 'Yearly'). That means they make 90000.0 a year\n",
      "This person is earns (9500.0, 'Monthly'). That means they make 114000.0 a year\n",
      "This person is earns (3000.0, 'Monthly'). That means they make 36000.0 a year\n",
      "This person is earns (103000.0, 'Yearly'). That means they make 103000.0 a year\n",
      "This person is earns (69000.0, 'Yearly'). That means they make 69000.0 a year\n",
      "This person is earns (8000.0, 'Monthly'). That means they make 96000.0 a year\n",
      "This person is earns (7000.0, 'Monthly'). That means they make 84000.0 a year\n",
      "This person is earns (114000.0, 'Yearly'). That means they make 114000.0 a year\n",
      "This person is earns (2000.0, 'Weekly'). That means they make 104000.0 a year\n",
      "This person is earns (22000.0, 'Weekly'). That means they make 1144000.0 a year\n",
      "This person is earns (96000.0, 'Monthly'). That means they make 1152000.0 a year\n",
      "This person is earns (156000.0, 'Yearly'). That means they make 156000.0 a year\n",
      "This person is earns (18000.0, 'Yearly'). That means they make 18000.0 a year\n",
      "This person is earns (6400.0, 'Monthly'). That means they make 76800.0 a year\n",
      "This person is earns (5000.0, 'Monthly'). That means they make 60000.0 a year\n",
      "This person is earns (400000.0, 'Yearly'). That means they make 400000.0 a year\n"
     ]
    }
   ],
   "source": [
    "# now I can test how these work together\n",
    "for i, row in df.head(20).iterrows():\n",
    "    period = row[\"CompFreq\"]\n",
    "    payment = row[\"CompTotal\"]\n",
    "    \n",
    "    # we can run the caluclation on our data\n",
    "    calc_result = compensation_calc(frequency=period, compensation=payment)\n",
    "    \n",
    "    # with this we can check with a statement\n",
    "    print(f\"This person is earns {payment, period}. That means they make {calc_result} a year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61000.0, 138000.0, 90000.0, 348000.0, 90000.0, 114000.0, 36000.0, 103000.0, 69000.0, 96000.0, 84000.0, 114000.0, 104000.0, 1144000.0, 1152000.0, 156000.0, 18000.0, 76800.0, 60000.0, 400000.0]\n"
     ]
    }
   ],
   "source": [
    "# now I'm going to add it to a list to add to my dataframe\n",
    "\n",
    "# first I will make a list\n",
    "total_comp = []\n",
    "\n",
    "#now I'm going to add my data to the list\n",
    "for i, row in df.head(20).iterrows():\n",
    "    period = row[\"CompFreq\"]\n",
    "    payment = row[\"CompTotal\"]    \n",
    "    calc_result = compensation_calc(frequency=period, compensation=payment)\n",
    "    \n",
    "    total_comp.append(calc_result)\n",
    "    \n",
    "print(total_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I am going to shorten my code and run it on the whole frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comp = []\n",
    "\n",
    "for i, row in df.iterrows():   \n",
    "    calc_result = compensation_calc(frequency=row[\"CompFreq\"], compensation=row[\"CompTotal\"])    \n",
    "    total_comp.append(calc_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11398, 85)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then I will check my list to see if it matches my dataframe    \n",
    "print(len(total_comp))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so to make a new column you can just use name_of_dataframe[name_of_column] = series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comp = []\n",
    "\n",
    "for i, row in df.iterrows():   \n",
    "    calc_result = compensation_calc(frequency=row[\"CompFreq\"], compensation=row[\"CompTotal\"])    \n",
    "    total_comp.append(calc_result)\n",
    "    \n",
    "df[\"NormalizedAnnualCompensation\"] = total_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11398, 86)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
